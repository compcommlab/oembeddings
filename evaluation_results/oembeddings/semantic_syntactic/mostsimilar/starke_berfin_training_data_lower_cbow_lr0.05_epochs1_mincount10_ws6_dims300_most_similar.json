[
 {
  "task_group": "most_similar_groups",
  "task": "nouns: SI/PL",
  "correct": 83,
  "top_n": 202,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.206868171691895,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "nouns: PL/SI",
  "correct": 48,
  "top_n": 136,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 17.391255378723145,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: GR/KOM",
  "correct": 241,
  "top_n": 385,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 20.06200623512268,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: KOM/GR",
  "correct": 174,
  "top_n": 330,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 19.8010151386261,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: GR/SUP",
  "correct": 265,
  "top_n": 352,
  "n": 10,
  "coverage": 418,
  "total_questions": 500,
  "duration": 19.198391437530518,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: SUP/GR",
  "correct": 120,
  "top_n": 225,
  "n": 10,
  "coverage": 399,
  "total_questions": 500,
  "duration": 18.57242226600647,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: KOM/SUP",
  "correct": 302,
  "top_n": 371,
  "n": 10,
  "coverage": 407,
  "total_questions": 500,
  "duration": 19.267204999923706,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: SUP/KOM",
  "correct": 124,
  "top_n": 305,
  "n": 10,
  "coverage": 405,
  "total_questions": 500,
  "duration": 18.96712040901184,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): INF/1SP",
  "correct": 281,
  "top_n": 410,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 17.64979577064514,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 1SP/INF",
  "correct": 393,
  "top_n": 462,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.402443408966064,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): INF/2PP",
  "correct": 237,
  "top_n": 359,
  "n": 10,
  "coverage": 488,
  "total_questions": 500,
  "duration": 19.655888319015503,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 2PP/INF",
  "correct": 301,
  "top_n": 418,
  "n": 10,
  "coverage": 487,
  "total_questions": 500,
  "duration": 18.608381271362305,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 1SP/2PP",
  "correct": 208,
  "top_n": 321,
  "n": 10,
  "coverage": 490,
  "total_questions": 500,
  "duration": 19.64099097251892,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 2PP/1SP",
  "correct": 224,
  "top_n": 340,
  "n": 10,
  "coverage": 486,
  "total_questions": 500,
  "duration": 18.333056211471558,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): INF/3SV",
  "correct": 251,
  "top_n": 356,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.855458974838257,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3SV/INF",
  "correct": 216,
  "top_n": 394,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.449488162994385,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): INF/3PV",
  "correct": 282,
  "top_n": 393,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.83402156829834,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3PV/INF",
  "correct": 304,
  "top_n": 409,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 18.41143012046814,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3SV/3PV",
  "correct": 442,
  "top_n": 492,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 19.119874477386475,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3PV/3SV",
  "correct": 401,
  "top_n": 465,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 19.20449924468994,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "total",
  "correct": 4897,
  "top_n": 7125,
  "n": 10,
  "coverage": 9580,
  "total_questions": 10000,
  "duration": 376.6316125392914,
  "name": "starke_berfin",
  "parameter_string": "training_data_lower_cbow_lr0.05_epochs1_mincount10_ws6_dims300"
 }
]