[
 {
  "task_group": "most_similar_groups",
  "task": "nouns: SI/PL",
  "correct": 147,
  "top_n": 340,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.5288994312286377,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "nouns: PL/SI",
  "correct": 96,
  "top_n": 280,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.4786880016326904,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: GR/KOM",
  "correct": 292,
  "top_n": 419,
  "n": 10,
  "coverage": 487,
  "total_questions": 500,
  "duration": 2.8148224353790283,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: KOM/GR",
  "correct": 223,
  "top_n": 407,
  "n": 10,
  "coverage": 481,
  "total_questions": 500,
  "duration": 2.854412078857422,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: GR/SUP",
  "correct": 196,
  "top_n": 262,
  "n": 10,
  "coverage": 280,
  "total_questions": 500,
  "duration": 3.2675349712371826,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: SUP/GR",
  "correct": 106,
  "top_n": 201,
  "n": 10,
  "coverage": 271,
  "total_questions": 500,
  "duration": 3.189929723739624,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: KOM/SUP",
  "correct": 168,
  "top_n": 253,
  "n": 10,
  "coverage": 271,
  "total_questions": 500,
  "duration": 3.4172544479370117,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "adjectives: SUP/KOM",
  "correct": 121,
  "top_n": 244,
  "n": 10,
  "coverage": 276,
  "total_questions": 500,
  "duration": 3.1969501972198486,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): INF/1SP",
  "correct": 396,
  "top_n": 491,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.617030620574951,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 1SP/INF",
  "correct": 453,
  "top_n": 493,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.582885503768921,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): INF/2PP",
  "correct": 276,
  "top_n": 394,
  "n": 10,
  "coverage": 455,
  "total_questions": 500,
  "duration": 3.0620155334472656,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 2PP/INF",
  "correct": 362,
  "top_n": 420,
  "n": 10,
  "coverage": 448,
  "total_questions": 500,
  "duration": 3.1172852516174316,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 1SP/2PP",
  "correct": 252,
  "top_n": 371,
  "n": 10,
  "coverage": 455,
  "total_questions": 500,
  "duration": 3.1740150451660156,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (pres): 2PP/1SP",
  "correct": 291,
  "top_n": 381,
  "n": 10,
  "coverage": 450,
  "total_questions": 500,
  "duration": 3.2057149410247803,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): INF/3SV",
  "correct": 353,
  "top_n": 442,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.264620065689087,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3SV/INF",
  "correct": 329,
  "top_n": 448,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.4412147998809814,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): INF/3PV",
  "correct": 341,
  "top_n": 447,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.2158315181732178,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3PV/INF",
  "correct": 371,
  "top_n": 436,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.563903331756592,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3SV/3PV",
  "correct": 490,
  "top_n": 500,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.265817165374756,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "verbs (past): 3PV/3SV",
  "correct": 453,
  "top_n": 497,
  "n": 10,
  "coverage": 500,
  "total_questions": 500,
  "duration": 2.4411680698394775,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 },
 {
  "task_group": "most_similar_groups",
  "task": "total",
  "correct": 5716,
  "top_n": 7726,
  "n": 10,
  "coverage": 8874,
  "total_questions": 10000,
  "duration": 55.69999313354492,
  "name": "beliebte_allegra",
  "parameter_string": "training_data_cbow_lr0.05_epochs1_mincount100_ws24_dims300"
 }
]